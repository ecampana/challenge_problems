{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization: Binomial Mixture Model\n",
    "\n",
    "__Notebook by Emmanuel Contreras-Campana, PhD__\n",
    "\n",
    "The Expectation Maximization algorithm is an iterative method for finding maximum likelihood (MLE) or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin Flip Experiment\n",
    "\n",
    "As an example, consider a simple coin-flipping experiment in which we are given a pair of coins A and B of unknown biases, $\\theta_A$ and $\\theta_B$, respectively (that is, on any given flip, coin A will land on heads with probability $\\theta_A$ and tails with probability $1-\\theta_A$ and similarly for coin B). Our goal is to estimate $\\theta = (\\theta_A,\\ \\theta_B)$ by repeating the following procedure several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coin likelihood\n",
    "def binomial_likelihood(num_heads, trials, bias):\n",
    "    \"\"\"\n",
    "    Calcuate binomial likelihood\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs : list\n",
    "        observations (i.e. rolls)\n",
    "    bias : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    \n",
    "    # number of successes\n",
    "    \n",
    "    # number of tosses\n",
    "    Returns\n",
    "    -------\n",
    "    likelihood : float\n",
    "        likelihood of drawing the coin to perform experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    # likelihood P(X | theta)\n",
    "    likelihood = scipy.stats.binom(trials, bias).pmf(num_heads)\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expectation step\n",
    "def expection_step(observations, theta_A, theta_B,\n",
    "                   prior_A):\n",
    "    \"\"\"\n",
    "    Calculate the expected number of heads and tails attributed\n",
    "    to coin A as well as the expected number of heads and tails\n",
    "    attributed to coin B\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : list of lists\n",
    "        observations (i.e. list of rolls)\n",
    "    theta_A : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    theta_B : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    heads_A, tails_A, heads_B, tails_B : floats\n",
    "    \"\"\"\n",
    "    \n",
    "    heads = []\n",
    "    tails = []\n",
    "         \n",
    "    # expected number of heads/tails attributed to coin A\n",
    "    gamma_A = []\n",
    "\n",
    "    # expected number of heads/tails attributed to coin B\n",
    "    gamma_B = []\n",
    "    \n",
    "    # prior distribution for drawing coin B\n",
    "    prior_B = 1 - prior_A\n",
    "    \n",
    "    for rolls in observations:\n",
    "        \n",
    "        # number of heads in each set of rolls\n",
    "        num_heads = rolls.count(\"H\")\n",
    "        trails = len(rolls)\n",
    "        \n",
    "        # likelihood of each coin\n",
    "        likelihood_A = binomial_likelihood(num_heads, trails, theta_A)\n",
    "        \n",
    "        likelihood_B = binomial_likelihood(num_heads, trails, theta_B)\n",
    "        \n",
    "        # evidence of the data\n",
    "        p_D = likelihood_A*prior_A + likelihood_B*prior_B\n",
    "        \n",
    "        # posterior distributions for drawing coins A or B\n",
    "        # note: Bayes' theorem\n",
    "        p_A = likelihood_A*prior_A/p_D\n",
    "        \n",
    "        # expected number of heads and tails attributed\n",
    "        # to coin A\n",
    "        gamma_A.append(p_A)\n",
    "        \n",
    "        heads.append(num_heads)\n",
    "        \n",
    "    return gamma_A, heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximization algorith for coin flips\n",
    "def  maximization_step(gamma_A, heads):\n",
    "    \"\"\"\n",
    "    Obtain the maximum likelihood estimator theta (i.e. theta MLE)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    heads_A : list of lists\n",
    "        observations (i.e. list of rolls)\n",
    "    tails_A : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    heads_B : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    tails_B : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta_A, theta_B : float\n",
    "        likelihood of drawing the coin to perform experiment\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace dummy values with your implementation\n",
    "    size = len(gamma_A)\n",
    "    gamma_B = np.array([1]*size) - np.array(gamma_A)\n",
    "    \n",
    "    tails = np.array([10]*5) - np.array(heads)\n",
    "    \n",
    "    exp_heads_A = np.array(heads)*np.array(gamma_A)\n",
    "    exp_tails_A = np.array(tails)*np.array(gamma_A)\n",
    "    \n",
    "    theta_A = np.sum(exp_heads_A)/(np.sum(exp_heads_A) + np.sum(exp_tails_A))\n",
    "    \n",
    "    exp_heads_B = np.array(heads)*np.array(gamma_B)\n",
    "    exp_tails_B = np.array(tails)*np.array(gamma_B)\n",
    "\n",
    "    theta_B = np.sum(exp_heads_B)/(np.sum(exp_heads_B) + np.sum(exp_tails_B))\n",
    "    \n",
    "    prior_A = np.mean(gamma_A)\n",
    "    \n",
    "    return theta_A, theta_B, prior_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expectation maximization algorithm for coin flips\n",
    "def expectation_maximization(rolls, theta_A, theta_B,\n",
    "                             prior_A, max_iter=10):\n",
    "    \"\"\"\n",
    "    Expectation Maximization (EM) algorithm for Binomial Mixture Model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rolls : list of lists\n",
    "        observations of all the rolls\n",
    "    theta_A : float\n",
    "        bias of coin A (i.e. probability of success for the coin)\n",
    "    theta_B : float\n",
    "        bias of coin B (i.e. probability of success for the coin)\n",
    "    max_iter : float\n",
    "        the number of iterations to use for EM algorithm\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    thetas : float\n",
    "        list of all thetas calculated with EM algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    # store biases of coin from each iteration\n",
    "    thetas = []\n",
    "    \n",
    "    # Iterate through EM algorithm\n",
    "    for i in range(max_iter+1):\n",
    "        \n",
    "        # store initial biases of coins\n",
    "        if i==0:\n",
    "            thetas.append((theta_A, theta_B))\n",
    "\n",
    "        # store updated biases of coins\n",
    "        else:\n",
    "            # perform expectation step\n",
    "            gamma_A, heads = expection_step(rolls, theta_A, theta_B,\n",
    "                                            prior_A)\n",
    "\n",
    "            # perform maximization step\n",
    "            theta_A, theta_B, prior_A = maximization_step(gamma_A, heads)\n",
    "\n",
    "            # rounding\n",
    "            theta_A = float(format(theta_A, '.2f'))\n",
    "            theta_B = float(format(theta_B, '.2f'))\n",
    "\n",
    "            # all theta values\n",
    "            thetas.append((theta_A, theta_B))\n",
    "        \n",
    "        print \"#%d:\\t%0.2f %0.2f (prior %0.2f)\" % (i, theta_A, theta_B, prior_A)\n",
    "        \n",
    "    thetas = np.array(thetas)\n",
    "    \n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# intial random guess for biases of coins\n",
    "theta_A = 0.6\n",
    "theta_B = 0.5\n",
    "\n",
    "# initial random guess for the probability of drawing each coin\n",
    "prior_A = 0.45 # mixing proportion\n",
    "\n",
    "# number of interations to perform\n",
    "max_iter = 10\n",
    "\n",
    "# set of observations\n",
    "rolls = [ \"HTTTHHTHTH\", \"HHHHTHHHHH\", \"HTHHHHHTHH\", \n",
    "          \"HTHTTTHHTT\", \"THHHTHHHTH\" ]\n",
    "\n",
    "thetas = expectation_maximization(rolls, theta_A, theta_B, \n",
    "                                  prior_A, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coin likelihood\n",
    "def binom_likelihood(obs, bias):\n",
    "    \"\"\"\n",
    "    Calcuate binomial likelihood\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs : list\n",
    "        observations (i.e. rolls)\n",
    "    bias : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    likelihood : float\n",
    "        likelihood of drawing the coin to perform experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of successes\n",
    "    num_heads = obs.count(\"H\")\n",
    "    \n",
    "    # number of tosses\n",
    "    trials = len(obs)\n",
    "    \n",
    "    # likelihood P(X | theta)\n",
    "    likelihood = pow(bias, num_heads) * pow(1 - bias, trials - num_heads)\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expectation step\n",
    "def e_step(observations, theta_A, theta_B):\n",
    "    \"\"\"\n",
    "    Calculate the expected number of heads and tails attributed\n",
    "    to coin A as well as the expected number of heads and tails\n",
    "    attributed to coin B\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : list of lists\n",
    "        observations (i.e. list of rolls)\n",
    "    theta_A : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    theta_B : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    heads_A, tails_A, heads_B, tails_B : floats\n",
    "    \"\"\"\n",
    "    \n",
    "    # expected number of heads/tails attributed to coin A\n",
    "    heads_A =0\n",
    "    tails_A = 0\n",
    "    \n",
    "    # expected number of heads/tails attributed to coin B\n",
    "    heads_B = 0\n",
    "    tails_B = 0\n",
    "    \n",
    "    for rolls in observations:\n",
    "        likelihood_A = binom_likelihood(rolls, theta_A)\n",
    "        likelihood_B = binom_likelihood(rolls, theta_B)\n",
    "        \n",
    "        # improper priors for drawing coins A or B\n",
    "        prior_A = 1/(likelihood_A + likelihood_B)\n",
    "        prior_B = prior_A\n",
    "        \n",
    "        # posterior distributions for drawing coins A or B\n",
    "        p_A = likelihood_A * prior_A\n",
    "        p_B = likelihood_B * prior_B\n",
    "        \n",
    "        # expected number of heads and tails attributed\n",
    "        # to coin A\n",
    "        heads_A += p_A * rolls.count(\"H\")\n",
    "        tails_A += p_A * rolls.count(\"T\")\n",
    "        \n",
    "        # expected number of heads and tails attributed\n",
    "        # to coin B\n",
    "        heads_B += p_B * rolls.count(\"H\")\n",
    "        tails_B += p_B * rolls.count(\"T\")\n",
    "        \n",
    "    return heads_A, tails_A, heads_B, tails_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximization algorith for coin flips\n",
    "def  m_step(heads_A, tails_A, heads_B, tails_B):\n",
    "    \"\"\"\n",
    "    Obtain the maximum likelihood estimator theta (i.e. theta MLE)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    heads_A : list of lists\n",
    "        observations (i.e. list of rolls)\n",
    "    tails_A : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    heads_B : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    tails_B : float\n",
    "        bias of coin (i.e. probability of success for the coin)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta_A, theta_B : float\n",
    "        likelihood of drawing the coin to perform experiment\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace dummy values with your implementation\n",
    "    theta_A = heads_A / (heads_A + tails_A)\n",
    "    theta_B = heads_B / (heads_B + tails_B)\n",
    "    \n",
    "    return theta_A, theta_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expectation maximization algorithm for coin flips\n",
    "def em_algorithm(rolls, theta_A, theta_B, max_iter=10):\n",
    "    \"\"\"\n",
    "    Expectation Maximization (EM) algorithm for Binomial Mixture Model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rolls : list of lists\n",
    "        observations of all the rolls\n",
    "    theta_A : float\n",
    "        bias of coin A (i.e. probability of success for the coin)\n",
    "    theta_B : float\n",
    "        bias of coin B (i.e. probability of success for the coin)\n",
    "    max_iter : float\n",
    "        the number of iterations to use for EM algorithm\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    thetas : float\n",
    "        list of all thetas calculated with EM algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    # store biases of coin from each iteration\n",
    "    thetas = []\n",
    "    \n",
    "    # Iterate through EM algorithm\n",
    "    for i in range(max_iter+1):\n",
    "        \n",
    "        # store initial biases of coins\n",
    "        if i==0:\n",
    "            thetas.append((theta_A, theta_B))\n",
    "\n",
    "        # store updated biases of coins\n",
    "        else:\n",
    "            # perform expectation step\n",
    "            heads_A, tails_A, heads_B, tails_B = e_step(rolls, theta_A, theta_B)\n",
    "\n",
    "            # perform maximization step\n",
    "            theta_A, theta_B = m_step(heads_A, tails_A, heads_B, tails_B)\n",
    "\n",
    "            # rounding\n",
    "            theta_A = float(format(theta_A, '.2f'))\n",
    "            theta_B = float(format(theta_B, '.2f'))\n",
    "\n",
    "            # all theta values\n",
    "            thetas.append((theta_A, theta_B))\n",
    "        \n",
    "        print(\"#%d:\\t%0.2f %0.2f\" % (i, theta_A, theta_B))\n",
    "        \n",
    "    thetas = np.array(thetas)\n",
    "    \n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intial random guess for biases of coins\n",
    "theta_A = 0.6\n",
    "theta_B = 0.5\n",
    "\n",
    "# number of interations to perform\n",
    "max_iter = 10\n",
    "\n",
    "# set of observations\n",
    "rolls = [ \"HTTTHHTHTH\", \"HHHHTHHHHH\", \"HTHHHHHTHH\", \n",
    "          \"HTHTTTHHTT\", \"THHHTHHHTH\" ]\n",
    "\n",
    "thetas = em_algorithm(rolls, theta_A, theta_B, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n",
    "0. http://statisticalrecipes.blogspot.com/2012/04/applying-em-algorithm-binomial-mixtures.html\n",
    "1. http://karlrosaen.com/ml/notebooks/em-coin-flips/\n",
    "2. https://www.youtube.com/watch?v=TBouIiMZNf0\n",
    "3. https://www.youtube.com/watch?v=7e65vXZEv5Q\n",
    "4. https://www.youtube.com/watch?v=Ps2qV9vCn60\n",
    "5. https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm\n",
    "6. https://cs.stackexchange.com/questions/10637/applying-expectation-maximization-to-coin-toss-examples\n",
    "7. https://www.youtube.com/watch?v=AnbiNaVp3eQ\n",
    "8. https://www.youtube.com/watch?v=xpkaTRxzQ2k\n",
    "9. https://www.youtube.com/watch?v=-q0KFRaPuvc\n",
    "10. http://dawenl.github.io/files/em.pdf\n",
    "11. http://local.disia.unifi.it/grilli/files/Papers/BinomialMixtureModellingCredits.pdf\n",
    "12. https://www.cs.cmu.edu/~tom/10701_sp11/recitations/EM%20Algorithm.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
